uids-site
=========
Сайт-экзаменационное задание для школы разработки интерфейсов Яндекса

#### Как это заставить работать?
Корень всего - `grunt`. У него есть несколько задач, которые собирают необходимый контент для страницы:
* stylus. Препроцессор css.
* uglify. Минимизирует JS.
* html-minify. Минимизирует html. Хотя можно лучше, как мне показалось.
* imagemin. Минимизирует изображения.
* copy. Копирует файлы в папку с результирующим сайтом.

Они дополнены собственными задачами:
* compileDot. Делает из dot-шаблонов яваскриптовые функции и собирает в файл. Возможно, я неправильно готовил тот, что нашёл в рерозитории, но он вёл себя странно и не так, как мне нужно.
* concatJS. Собирает js-файлы в один, оборачивая в самовыполняемую функцию.
* concatJSON. Собирает json-файлы в один js-файл, который представляет собой объект с нужными данными.
* loadImages. Очень странная штука, которая по списку пользователей грузит их фотографии, делает уменьшенные версии изображения, а также собирает json-файл с информацией о всём этом. Выполняется только один раз, для уменьшения времени работы в разработке. Определяет это по наличию загруженных файлов.
* mergeJSON. Объединяет информацию о людях и информацию об их загруженных фотографиях в один файл.
* processLinks. Обрабатывает ссылки в json-файле с людьми, чтобы все ссылки были одного вида.

Все задачи сгруппированы в 2 блока: общий и `production`. В обычном блоке выключены многие оптимизации: изображений, js, html, и заменены на простое копирование.

Во время работы создаётся временная папка `work`, в которой лежат не полностью обработанные файлы. Результат работы - сайт, лежит в папке `out`.

Список лекций был распарсен с сайта Яндекса о ШРИ. Скрипт, делающий это, лежит в `tools/parseLectures.js`. Предполагалось, что его будут запускать из консоли в браузере, в котором открыт список лекций.

Список людей был получен из клуба, в котором люди оставляли информацию о себе. Похоже, не все люди оставляли инфу.